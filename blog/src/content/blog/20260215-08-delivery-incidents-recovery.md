---
title: "깃헙액션이랑 엮인 배포가 깃헙의 서비스 상태에 영향을 받다보니 깃헙스테이터스 알림을 슬랙채널로 받게 팀원분이 작업을 해두셨다."
description: "외부 CI 의존성, 서버리스 DB 불안정, 큐 증폭 버그를 겪으며 배포와 복구 기준을 다시 세운 기록."
pubDate: 2024-08-27T23:19:19+00:00
source: twitter
tags:
  - 배포
  - 장애대응
  - GitHubActions
  - AWS
  - SQS
  - 운영
---

우리 배포는 GitHub Actions에 묶여 있었고, GitHub 상태가 흔들리면 배포 흐름도 같이 흔들렸다. 팀원이 GitHub Status 알림을 Slack으로 연결해둔 뒤에야 이게 가끔 있는 이벤트가 아니라는 걸 체감했다. 2024-08-27에도 장애 알림이 이어졌고, 잠시 뒤 resolved 알림이 떴다. 그날 정리한 결론은 단순했다. 배포 속도 문제가 아니라, 외부 의존성 상태를 모르고 일정을 고정하는 방식이 문제였다.

그 이후 배포 판단 기준을 코드 변경량에서 시스템 상태로 옮겼다. 외부 CI가 불안정하면 배포를 밀어붙이지 않고 대기하거나 범위를 줄였고, 내부 이슈는 작게 나눠서 빠르게 닫았다. 2024-10-29처럼 실사용 이슈가 여러 건 동시에 올라올 때는 특히 급한 복구와 구조 수정을 분리해야 했다. 백오피스는 당장 이탈이 적다는 이유로 임시조치가 길어지기 쉬운데, 그 습관이 다음 장애의 원인이 되기 쉬웠다.

DB 쪽에서는 서버리스 클러스터가 한 달에 한 번꼴로 재기동되는 문제가 계속됐다. 점진적으로 바꾸겠다고 시작한 구성을 중간 상태로 오래 둔 선택이 운영 리스크가 됐다. 이 구간은 기능 개발팀 혼자 해결하기보다 데브옵스와 역할을 분리하는 편이 맞았다. 나는 증상, 재현 조건, 영향 범위를 짧게 정리해 전달하고, 인프라 변경은 담당 절차로 일관되게 진행하는 방식으로 맞췄다. 외부 서비스의 내부 사정까지는 우리가 정확히 알 수 없다는 한계도 같이 받아들였다.

가장 크게 배운 건 큐 사고였다. 실패 메시지를 삭제하지 않은 채 서킷브레이커를 피해 다시 SQS에 넣는 버그 때문에 테스트 메시지 1개가 5분 만에 300만 개로 증식했고, CPU 부하 오토스케일링으로 노드까지 늘어났다. 이 뒤로는 실패 처리 규칙을 기능보다 먼저 고정했다. 재시도 횟수와 간격, 폐기 조건을 코드에 명시하고, 배포 전 점검의 첫 줄을 “실패가 반복될 때 어디서 멈추는가”로 바꿨다. 장애 자체를 완전히 없애긴 어려워도, 증폭 경로를 닫는 설계는 미리 할 수 있다는 점은 분명했다.
