---
title: "@ujuc 음, 요즘 클로드가 해메는 상황을 제미나이가 풀어준 적이 몇번 있어서 좀 이것도 좀 멀티 구성을 해야하나 싶어지네요 ㅎ"
description: "계획, 개발, 문서 작업에 AI를 붙여 얻은 속도와 모델 편차·API 제약·검토 비용 같은 실제 마찰을 정리했다."
pubDate: 2025-02-28T01:01:56+00:00
source: twitter
tags:
  - ai-workflow
  - llm
  - 개발프로세스
  - 문서화
---

요즘은 AI를 단순 보조가 아니라 작업 공정으로 쓰고 있다. 초안 작성, 팀별 배포 문서, 로드맵 기반 마일스톤 정리와 이슈보드 등록까지 한 번에 돌려봤다. 체감 속도는 분명히 올라갔다. 대신 병목도 선명했다. 같은 요청인데 어떤 날은 잘 되고, 어떤 날은 같은 모델이 계속 헤맨다. 그 순간 다른 모델이 바로 해결한 일이 몇 번 나오면서 단일 모델 고정이 맞는지 의문이 생겼다.

실행에서 먼저 바꾼 건 프롬프트 길이가 아니라 기준 입력이었다. 잘 안 먹히는 날에는 잘 됐던 결과를 few-shot으로 붙여 출력 형태를 고정했다. 계획, 구현, 문서처럼 산출물 성격이 다른 일은 단계별로 나눠 모델을 다르게 써봤다. 다만 나는 주로 구독형 제품을 쓰고 있어서 API 라우팅으로 자동 전환하는 구성을 만들기 쉽지 않았다. 결국 일부는 수동 전환, 수동 검토가 남았다.

이 방식으로 얻은 이익은 초기 세팅 속도였다. 로드맵에서 마일스톤을 만들고 개발 이슈를 생성해 보드에 올리는 구간은 확실히 빨라졌다. 반대로 문서는 생성량이 늘수록 검토 부담이 커졌다. 팀별 맥락 차이 때문에 표현을 다시 맞추는 시간이 계속 필요했다. 생성 비용은 내려가도 승인 비용은 쉽게 줄지 않았다. 현재 기록만으로는 어느 모델이 항상 더 낫다고 단정할 근거도 충분하지 않다.

그래서 지금은 모델 비교보다 검토 단위를 먼저 설계한다. 산출물마다 최소 합격 기준을 짧게 정의하고, 잘 먹힌 few-shot은 템플릿으로 재사용한다. 막히는 구간에서는 보조 모델을 바로 투입하되, 자동화가 어려운 환경이라면 전환 횟수와 리뷰 시간을 일정에 포함한다. AI 워크플로에서 중요한 건 더 많이 생성하는 일이 아니라, 팀이 통제 가능한 품질로 끝까지 가져가는 일이라고 보고 있다.
