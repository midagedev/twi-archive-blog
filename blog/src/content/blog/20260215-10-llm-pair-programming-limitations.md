---
title: 'LLM 페어 프로그래밍에서 엔지니어링 판단을 잃지 않으려면'
description: '검색과 삽질 시간을 줄여 집중을 늘리되, 모델 품질 차이와 도구 한계를 감안해 사람의 판단을 끝까지 유지한 작업 방식을 정리했다.'
pubDate: 2023-04-08T14:02:09+00:00
source: twitter
tags:
  - llm
  - pair-programming
  - engineering
  - workflow
---

ChatGPT와 페어 프로그래밍을 많이 해본 시기에 가장 크게 변한 건 코드 생성량보다 흐름 유지였다. 막힐 때마다 검색 탭을 늘리던 시간이 줄고, 같은 맥락 안에서 대안을 바로 비교할 수 있었다. 덕분에 집중이 끊기는 횟수가 줄었고, 4시간 정도 연속으로 코딩해도 피로감이 덜했다. 다만 초반부터 분명했던 한계도 있었다. 프롬프트의 수준이 내 이해를 크게 넘지 못하면, 답의 상한도 결국 내가 찾을 수 있는 범위를 크게 벗어나지 않는다.

그래서 사용 원칙을 단순하게 잡았다. 모델에게 설계를 맡기기보다 선택지 정리, 초기 초안, 디버깅 실마리처럼 탐색 구간을 빠르게 통과하는 데 썼다. 받은 답은 바로 실행 결과와 코드 맥락으로 검증하고, 맞지 않으면 즉시 버렸다. 이 방식은 체력과 집중력을 갉아먹던 반복 시행착오를 줄이는 데 효과가 있었다. 반면 생산성 개선 폭을 따로 계량해 두지는 못해서, 체감 외의 정량 비교는 아직 어렵다.

모델을 바꿔보면 차이는 더 명확했다. 비슷한 작업을 시켜도 어떤 모델은 문맥을 안정적으로 잇고, 어떤 모델은 환각성 답변이 늘어 검증 비용을 키웠다. 겉으로는 모두 도움을 주는 것처럼 보여도, 실무에서는 정확도와 일관성 차이가 바로 시간 손실로 이어졌다. 결국 중요한 건 최신 모델 이름보다 내 작업에서 신뢰 가능한 구간과 그렇지 않은 구간을 미리 나눠 두는 일이다.

도구 체인도 아직 완성형은 드물었다. 웹검색 같은 툴콜링을 기대했지만, 실제로는 서버를 추가로 붙이거나 준완성 조합을 직접 맞춰야 하는 경우가 있었다. 비용 대비 이득이 애매하면 임시 워크플로로 우회하는 편이 현실적이었다. 최근에는 GLM coding plan과 opencode 같은 조합으로 막힌 구간을 먼저 뚫고, 최종 판단과 책임은 사람 쪽에 남기는 식으로 운영했다. LLM을 정답 기계로 두면 실망이 커지고, 탐색 속도를 올리는 파트너로 두면 꾸준히 이득이 남는다.
