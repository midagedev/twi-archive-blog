---
title: 관측 스택을 줄여야 할 때 내가 본 기준
description: 지표 수집 오버헤드를 줄이기 위해 수집기를 교체하고, 데이터 검증 기준을 다시 세운 과정 정리.
pubDate: 2022-09-28T13:23:06+00:00
source: twitter
tags:
  - observability
  - monitoring
  - analytics
  - infra
---

처음 문제는 단순했다. 지표를 모으는 데 메모리 1GB를 쓰는 상태가 계속 유지되고 있었다. CPU 사용률만 보면 20%를 넘지 않는 구간이 많아 여유가 있어 보일 수 있지만, 운영 부담은 CPU 숫자 하나로 설명되지 않았다. 관측 도구도 기능 목록보다 런타임 비용과 유지 난이도로 다시 봐야 한다는 신호였다.

그래서 Grafana Alloy를 vmagent로 교체했다. 교체 후에는 Grafana Cloud에 연결된 Prometheus로 메트릭이 정상 전송되는지, 그리고 대시보드에서 같은 흐름으로 확인되는지부터 점검했다. 새 도구를 붙일 때 가장 먼저 본 건 “더 많은 기능”이 아니라 “기존 운영 시야를 잃지 않는가”였다.

결과는 분명했다. 수집 프로세스 메모리가 1GB 수준에서 100MB 미만으로 내려왔다. 이건 체감되는 비용 차이였다. 다만 여기서 바로 도구 자체의 우열을 단정하진 않았다. Alloy도 설정 최적화로 개선될 가능성은 있다. 이번 판단은 절대평가가 아니라, 현재 제약에서 어떤 조합이 맞는지 고른 선택에 가깝다.

비슷한 기준은 어낼리틱스에도 그대로 적용했다. GA4, Amplitude, Mixpanel을 같이 붙여 비교하고, 각 도구 수치만 믿지 않기 위해 이벤트 raw 데이터를 별도로 저장해 검증했다. 유료 플랜으로 넘어가기 전에 결정을 내려야 했기 때문이다. Elasticsearch도 로그 탐색 용도로 쓰면 평가가 좋고, 문서 DB처럼 쓰면 불만이 커지는 경우가 있다. 결국 핵심은 도구 이름이 아니라 용도 적합성, 검증 가능성, 그리고 자원 한도다.
