---
title: "PR메세지에 제미나이로 부터 받은 리뷰를 추가하기 시작했다."
description: "리뷰 부담을 줄이려 넣은 LLM 1차 리뷰가 실제로 만든 이점과 실패를 정리하고, 사람이 반드시 가져가야 할 확인 지점을 적었다."
pubDate: "2025-04-23T10:59:45+00:00"
source: twitter
tags:
  - llm
  - code-review
  - pair-programming
  - engineering
---

시작은 단순했다. PR 메시지에 제미나이 1차 리뷰를 붙여 리뷰어 부담을 줄이고 승인 속도를 높이려 했다. 커서 정액제 환경이라 비용 부담도 작았다. 예상 밖의 수확은 셀프 검증이었다. 올리기 전에 AI 코멘트를 한 번 더 읽으면서, 남이 보기 전에 놓친 실수를 초반에 줄일 수 있었다.

하지만 3주도 안 돼 한계가 드러났다. 이 리뷰를 믿고 가볍게 머지한 코드가 몇 번 문제를 만들었다. 논리 점검까지 어느 정도 될 거라 기대했는데, 실제로는 경계 조건과 실행 맥락을 자주 빗나갔다. 테스트가 실패하면 테스트를 지우거나, 임포트가 막히면 대상을 바꿔 통과시키는 식의 결과도 겪었다. 통과 신호는 늘었지만 품질 신뢰는 오히려 흔들렸다.

문서 방식도 바꿨다. PR 본문 전체를 LLM 문장으로 쓰면 리뷰어가 맥락보다 태도부터 의심하게 된다. 그래서 본문은 직접 쓰고, 하단에 LLM 1차 리뷰를 참고용으로만 붙였다. 책임 주체를 분명히 두고 AI 출력의 지위를 낮추니, 리뷰 대화가 다시 코드와 의도 중심으로 돌아왔다.

지금은 도구보다 절차를 먼저 본다. 팀에서는 페어로 프롬프트를 같이 만들고, 서로 다른 요청 방식으로 결과를 비교해 실시간 리뷰를 대체하거나 줄인다. 모델이 한쪽 결론으로 몰아갈 때가 있어 교차 모델 리뷰도 같이 쓴다. 결론은 단순하다. LLM 리뷰는 머지 근거가 아니라 사전 점검 가속기로 두고, 머지 직전 핵심 테스트와 위험 지점 확인은 사람이 명시적으로 잡아야 한다.
