---
title: "클로드코드 서브에이전트 써보고 있는데 이게 보기보다 넘어야 하는 장벽이 두텁다."
description: "서브에이전트에서 낮아지는 반응성을 다루기 위해 md+작은 스크립트, 짧은 피드백 루프, 프롬프트 리뷰를 묶어 운영한 방식과 한계를 정리했다."
pubDate: "2025-07-02T10:27:31+00:00"
source: "twitter"
tags: ["ai-workflow", "클로드코드", "개발생산성", "프롬프트리뷰"]
---

주변에서 AI를 어떻게 잘 쓰냐고 물으면 특별한 요령보다 정렬 속도를 먼저 말하게 된다. 요청이 어떻게 이해됐는지 빨리 확인하고, 어긋난 지점을 작은 단위로 바로 맞추는 반복이다. 그런데 클로드코드에서 서브에이전트로 넘어가면 이 루프가 갑자기 어려워진다. 작업의 시인성과 반응성이 떨어지고 피드백 간격이 넓어져서, 익숙한 방식으로는 초반 장벽이 두껍게 느껴졌다.

그래서 한쪽으로 몰지 않고 md와 작은 스크립트를 묶어 썼다. md에는 목표, 제약, 입력/출력 기대치를 짧게 고정하고, 스크립트에는 형식 검사나 반복 변환처럼 결정적인 부분만 맡겼다. 스크립트만 쓰면 입력이 조금만 달라져도 실패하고, 모델만 쓰면 결과가 쉽게 흔들린다. 둘을 같이 두면 서로의 약점을 메우는 구간이 분명히 생긴다.

실행할 때는 처음부터 완성된 도착지를 강하게 못 박지 않았다. 대신 중간 산출물이 나왔을 때 이 방향이 맞는지 판단할 기준을 먼저 정했다. 그리고 코드도 일부러 단순하게 요구했다. 세련된 구조보다 의도가 바로 읽히고 수정 비용이 낮은 형태가, 반복이 많은 작업에서는 실제로 더 안정적이었다.

이 방식은 개인 생산성으로 끝나면 효과가 제한적이었다. 팀 안에서 무엇이 적절한 엔지니어링인지 공감대가 있어야 코드 가독성 밖의 맥락까지 같이 전달된다. 그래서 AI가 끼는 작업에서는 코드 리뷰만으로 부족했고, 프롬프트도 리뷰 대상으로 올리는 습관이 필요했다. 어떤 가정으로 지시했는지가 드러나야 결과를 같은 기준으로 해석할 수 있었다.

정리하면 핵심은 큰 한 번보다 작은 정렬을 자주 반복하는 루프다. 서브에이전트의 피드백 간격 문제를 넘기 전까지는 답답하지만, 루프를 유지하면 작업 속도는 분명 좋아진다. 다만 개선 폭을 아직 정량으로 말할 근거는 없다. 지금도 결정성이 필요한 구간은 스크립트로 고정하고, 나머지를 모델에 맡기는 경계를 계속 다듬는 중이다.
