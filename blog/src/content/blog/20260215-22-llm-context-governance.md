---
title: LLM 워크플로우에서 컨텍스트와 실패를 운영하는 방법
description: 장기 컨텍스트 공유, 토큰 예산 확인, 다중 모델 검토의 한계를 바탕으로 AI 보조 개발의 재현성을 높인 실무 방식.
pubDate: 2025-07-03T10:50:15+00:00
source: twitter
tags:
  - llm
  - ai-workflow
  - context-governance
  - reliability
---

요즘 AI 코딩에서 먼저 부딪히는 건 모델 지능보다 컨텍스트 수명이다. 대화창을 길게 이어 붙이는 방식만으로는 맥락이 안정적으로 유지되지 않았다. 그래서 장기 컨텍스트는 파일시스템으로 분리해 두고, 사용자와 모델이 같은 문서를 기준으로 작업하게 만들었다. 작업 규칙, 결정 근거, 실패 기록을 대화가 아니라 파일에 남기는 게 기본 운영 방식이 됐다.

토큰 예산도 초반에 오해하기 쉬운 지점이었다. `/context`로 확인해보면 내가 추가한 지시보다 도구 자체 컨텍스트가 시작부터 크게 차지하는 경우가 있었다. 이걸 모르면 검증 과정을 과하게 길게 설계해서 정작 필요한 코드 맥락이 잘린다. 그래서 결과 확인 절차를 한 번 더 감싸서 원문을 다 붙이기보다 체크 항목 중심으로 압축해 전달했다. 품질 개선보다 먼저 예산 관리가 선행돼야 했다.

판단이 모호할 때는 수동으로 다중 모델 검토를 돌렸다. 한 모델의 결과를 다른 모델에 보내 피드백을 받고 다시 반영하는 루프다. 실제로 개선이 생긴 경우도 있었지만, 틀린 전제를 공유한 채 더 그럴듯하게 동조하는 실패도 반복해서 봤다. 모델 수를 늘리는 것만으로 신뢰도가 오르지 않는다는 점이 여기서 분명해졌다.

그래서 루프의 중심을 정답 생성에서 실패 감지로 옮겼다. 문제가 고쳐진 직후에 “다음에도 같은 품질을 내려면 무엇을 지켜야 하는가”를 묻고, 그 답을 `agents_md` 같은 운영 문서에 짧게 누적했다. 중요한 건 조언을 많이 모으는 게 아니라 다음 실행에서 바로 검사 가능한 규칙으로 바꾸는 일이다. 정량적으로 얼마나 좋아졌는지는 아직 충분히 측정하지 못했지만, 적어도 같은 유형의 실수 재발은 줄이기 쉬워졌다.

지금의 모델을 팀 동료처럼 장시간 자율 운영하는 건 아직 이르다고 본다. 짧은 피드백과 초안 작성에는 유용하지만, 긴 맥락에서 방향을 끝까지 지키는 일은 자주 흔들린다. 그래서 역할을 분리했다. 모델은 단기 산출과 점검, 사람은 방향 결정과 종료 조건을 맡는다. 이 경계를 명시하면 속도는 유지하면서도 잘못된 방향으로의 집단 동조를 줄일 수 있다.
