---
title: "@aronze 토론에 대한 워크플로우를 만들어본 적은 없고 주로 제가 판단이 모호할때 클로드의 결과를 코덱스와 제미나이에게 보내고"
description: "멀티모델 교차검증의 한계를 겪은 뒤, 피드백 기록과 컨텍스트 관리, 자기수정 루프로 실무 활용 방식을 바꾼 과정."
pubDate: 2023-07-12T02:55:19+00:00
source: twitter
tags:
  - ai-agent
  - coding-workflow
  - context-management
---

처음에는 절차 없이 썼다. 답이 애매하면 클로드 결과를 코덱스와 제미나이에 다시 보내고, 받은 피드백을 또 되먹이는 식으로 수동 왕복했다. 같은 프롬프트를 여러 번 돌려 더 마음에 드는 답을 고르는 경우도 많았다. 가끔은 개선됐지만, 틀린 전제를 공유하면 모델들이 같은 오답으로 수렴하는 경험도 자주 나왔다. 이때부터 AI를 검색처럼 쓰기보다, 짧은 페어 프로그래밍 상대로 다루는 편이 현실적이라고 봤다.

전환점은 정답 자체보다 루프를 설계한 뒤였다. 한 번 잘 풀린 순간에 “다음에도 이렇게 하려면 무엇을 고정해야 하나”를 묻고, 그 답을 `agents_md`에 누적했다. 또 에러를 사람이 계속 중계하지 않도록, 에이전트가 에러 확인-수정-재확인까지 먼저 돌게 했다. 결과 확인 단계가 컨텍스트를 빨리 태우면 그 검증 자체를 한 번 더 감싸서 토큰 사용을 줄였다. `/context`에서 기본 컨텍스트가 생각보다 크게 시작한다는 점도 운영 기준에 넣었다.

체감상 가장 달라진 건 왕복 비용이었다. 내가 메시지를 번역해 전달하는 시간이 줄고, 모델이 스스로 고칠 수 있는 구간이 늘었다. 그렇다고 동료 수준이라고 보긴 어렵다. 대화가 길어지면 집중이 무너지고, 확신은 큰데 틀린 답을 미는 순간이 여전히 있다. 당시 개선 폭을 수치로 남기진 못해 정량 비교는 어렵고, 최종 판단을 사람이 잡아야 한다는 원칙은 그대로다.

지금은 단순하게 운영한다. 멀티모델은 다수결이 아니라 오답 탐지 장치로 쓰고, 복구에 성공한 패턴은 바로 기록해 다음 세션 시작점으로 재사용한다. 마지막으로 사람 개입 전에 자기수정 루프를 한 번 더 돌린다. 완벽한 자동화는 아니지만, 이 세 가지를 지키면 일일 개발에서 실패 비용을 낮추는 데는 충분히 도움이 된다.
