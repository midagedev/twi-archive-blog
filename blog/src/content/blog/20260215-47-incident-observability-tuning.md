---
title: "흔한 개발자의 장애대응 (컨셉샷만 찍고 랙정리후 로비에서 작업중, 여러분 랙에서는 딴짓하면 안되욥)"
description: 재현이 어려운 장애를 다룰 때 조사 순서와 관측 도구의 비용을 어떻게 판단했는지 기록한 운영 메모.
pubDate: 2022-04-19T10:10:44+00:00
source: twitter
tags:
  - 장애대응
  - 관측성
  - 모니터링
  - 서버리스
---

예전에 장애가 터졌을 때 랙 앞에서 급하게 사진만 남기고, 정리할 것 정리한 뒤 로비에서 계속 대응한 적이 있다. 그때 중요했던 건 장면이 아니라 순서였다. 먼저 영향 범위를 줄이고, 바로 확인 가능한 신호를 확보하고, 그다음에 원인을 좁히는 흐름이다. 당일 복구는 끝났지만, 복구 완료와 원인 이해는 다른 단계라는 걸 다시 확인했다.

더 까다로웠던 건 재현이 잘 안 되는 유형이었다. 대략 4개월 전부터 한 달에 한두 번 발생했고, 최근에는 빈도가 조금 늘었지만 스케줄링 작업처럼 규칙적인 트리거는 보이지 않았다. 이런 상황에서 CPU 사용률이 20%를 넘지 않는다는 지표는 쉽게 안심 재료가 된다. 나도 처음에는 자원 부족이 아닐 거라고 판단했지만, 그 판단이 조사 범위를 너무 빨리 좁힐 수 있다는 피드백을 받고 관점을 다시 열었다. CPU가 낮아도 다른 축의 부하나 병목 가능성은 남아 있다.

관측성 스택도 같은 기준으로 다시 봤다. 지표 수집에만 메모리 1GB를 쓰는 상태는 운영 비용으로 과하다고 판단했다. 그래서 Grafana Alloy 대신 vmagent로 교체했고, 메모리 사용량은 100MB도 안 되는 수준으로 내려갔다. 수집 데이터는 Grafana Cloud에 연결된 Prometheus로 정상 전송됐고 대시보드에서도 그대로 확인됐다. Alloy를 더 최적화하면 결과가 달라질 수는 있겠지만, 당시 우선순위는 새 기능 실험보다 오버헤드 축소와 운영 단순화였다.

결국 장애 대응에서 먼저 정해야 하는 건 도구 이름보다 조사 순서와 판단 기준이다. 재현이 어려우면 규칙성을 억지로 만들기보다 발생 시점과 공통 경로를 꾸준히 쌓아 가설을 관리하는 편이 낫다. 그리고 모니터링 도구 자체의 리소스 비용도 서비스 리스크로 계산해야 한다. 아직 패턴을 완전히 설명한 건 아니라서, 결론을 단정하지 않고 가정을 열어 둔 채 관측 지점을 계속 다듬는 방식이 현실적이었다.
