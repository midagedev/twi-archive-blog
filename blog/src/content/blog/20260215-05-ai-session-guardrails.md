---
title: "@nameEO gpt4에 비해 환각이 많은 느낌이었습니다."
description: "LLM 코딩 작업에서 환각과 컨텍스트 붕괴를 줄이기 위해 세션 운영 방식을 바꾼 경험을 정리했다."
pubDate: 2023-04-14T04:42:10+00:00
source: twitter
tags:
  - llm
  - 개발생산성
  - 세션관리
  - 에이전트워크플로우
---

LLM을 코딩에 붙이면 초반 속도는 확실히 올라가지만, 세션이 길어질수록 답변 품질이 흔들리는 순간이 자주 왔다. 특히 어떤 모델은 GPT-4와 비교해 환각이 더 많다고 느꼈다. 방금 전까지 워크스페이스 소스를 기준으로 설명하던 답변이, 다음 턴에서 존재하지 않는 코드나 파일을 근거처럼 말하는 식이다. 같은 프롬프트를 다시 생성했을 때 결과가 달라지는 일도 반복돼서, 정답을 빨리 얻는 것보다 출력 안정성을 관리하는 일이 먼저가 됐다.

그래서 해결 포인트를 모델 성능 자체보다 세션 운영에서 찾았다. 대화가 길어져 조금이라도 답이 둔해졌다고 느껴지면, 현재 상태를 `context.md`로 짧게 남기고 새 세션으로 넘어간다. 요약에는 목표, 현재까지의 결정, 남은 선택지만 넣었다. 이 규칙을 적용하면 긴 대화를 억지로 이어갈 때보다 맥락 복원이 빨랐고, 잘못된 전제를 오래 끌고 가는 비용도 줄었다.

토큰을 많이 쓰는 작업은 한 세션에서 몰아 처리하지 않고 병렬로 쪼갰다. 예를 들면 기간을 연도 단위로 나눠 서브 에이전트에 각각 맡기고, 마지막에 결과를 합치는 방식이다. 이때 중요한 건 에이전트별 출력 형식을 먼저 맞추는 일이다. 형식이 맞아야 취합 단계에서 누락과 중복을 빠르게 확인할 수 있고, 사람이 최종 판단할 때도 검증 부담이 줄어든다.

물론 이 방식이 환각을 없애주진 않는다. 도구마다 세션 길이 제한 옵션이 있는지, 기본 컨텍스트가 어떤 도메인에 치우쳐 있는지는 별도로 확인이 필요하다. 실제로 인프라 맥락에는 강점이 있어 보여도 코딩 답변에서 미세하게 어긋나는 경우가 있었다. 그래서 지금 기준은 단순하다. 긴 세션을 버티게 하지 말고, 요약 후 재시작하고, 병렬 작업은 구조를 먼저 정한 뒤 합친다. 안정성은 모델 이름보다 운영 규칙에서 더 크게 나온다.
