---
title: AI 보조 코드 리뷰에 경계선을 다시 그은 이유
description: AI 리뷰를 신뢰해 가볍게 머지하던 흐름에서 문제를 겪은 뒤, 수동 검증과 테스트 기준을 다시 세운 과정.
pubDate: 2025-05-14T10:50:55+00:00
source: twitter
tags:
  - ai
  - 코드리뷰
  - 테스트
  - 개발회고
---

몇 주 전까지만 해도 AI 리뷰 코멘트가 논리적으로 맞아 보이면 비교적 가볍게 머지했다. 그런데 그렇게 넘긴 변경에서 문제가 몇 번 반복됐다. 리뷰 문장이 정돈되어 있어도 실제 실행 경로와 경계 조건까지 보장해주지는 않았다. 어떤 결함이 주로 치명적이었는지까지는 이 기록만으로 일반화하기 어렵지만, 그때부터 내 기준에서 `리뷰 통과`와 `머지 가능`은 같은 말이 아니게 됐다.

지금은 AI를 초안 검토자 정도로 둔다. 머지 직전에는 사람이 직접 확인해야 하는 항목을 따로 본다. 입력 조건이 바뀌는 지점, 기존 동작과 충돌할 수 있는 분기, 실패 시 영향 범위처럼 자동 리뷰가 놓치기 쉬운 부분은 코드 흐름을 손으로 다시 따라간다. 속도는 조금 느려져도, 책임 경계가 분명해지면 배포 후 수정 비용이 줄었다.

테스트에서도 비슷한 교정이 있었다. Claude Code가 지시받은 테스트 케이스를 만드는 일은 자주 봤지만, 일을 하기 위해 기존 코드를 충분히 읽고 컨텍스트로 삼는 모습은 기대보다 적었다. 나도 매번 핵심 테스트만 남기고 축약해달라고 요청하면서 테스트 품질 신호에 둔감해졌다. 이후에는 축약 자체보다 의도 보존을 먼저 확인하고, 빠른 확인은 IDE 내장 테스트 러너로 짧게 돌려 피드백 루프를 유지했다.

아직 완성된 답은 아니다. 유닛 테스트를 어디까지 자동으로 돌릴지 같은 범위 조정은 팀의 커밋 밀도와 작업 방식에 따라 계속 바뀐다. 다만 지금 분명한 원칙은 하나다. AI가 만든 코드와 리뷰는 `후보`로 받고, merge gate는 사람이 명시적으로 닫고 여는 쪽이 안전하다. 수제 코드가 늘어난 건 퇴보라기보다, 실패 비용이 큰 구간에 수동 판단을 다시 배치한 결과에 가깝다.
